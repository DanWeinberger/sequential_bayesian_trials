---
title: "Sequential trials"
output: html_document
date: '2022-12-08'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(rjags)
library(HDInterval)
library(dplyr, warn.conflicts = FALSE)
options(dplyr.summarise.inform = FALSE)

library(patchwork)
library(stringr)
library(pbapply)
library(parallel)
library(plotly)

library(ggplot2)
library(extraDistr)
source('./R/prior.data.func.R')
source('./R/call_jags.R')
source('./R/sim.data.R')
source('./R/jags_basic_pois.R')
source('./R/jags_modified_pois_commensurate_gamma.R') #NOTE, this is experimental version
source('./R/jags_modified_pois_commensurate_uniform.R') #NOTE, this is experimental version
source('./R/jags_modified_pois_commensurate_half_cauchy.R') #NOTE, this is experimental version

source('./R/caterplot.func.R')
source('./R/prior_post_compare.R')
source('./R/extract_parm.R')

source('./R/run_all_models.R')

N.sim=500


```

Prior for VE proposed <https://hbiostat.org/proj/covid19/bayesplan.html#operating-characteristics> (low probability of extreme effects, symmetric around 0) A skeptical prior as defined by Frank harrell has low probability of extremes (e.g., 5% prior probability that the effect is \>95% or 5% that it is the inverse )

```{r}

# p(RR<0.05) = P(RR>1/0.05) 

#IRR=0.05 = 95%VE 
#log(0.05) log(IRR)

#IRR=1.95   #-95%VE




hist(rnorm(10000, mean=0, sd=1.821))

mean(rnorm(10000, mean=0, sd=1.821) <log(0.05) ) #~5% of people have a VE of >95%
mean(rnorm(10000, mean=0, sd=1.821) >log(1/0.05) ) # ~5% of people have a VE of >-95%


prior.sd.logrr <- (abs(log(1-44.4/100)  -  log(1-19.6/100)))/1.96
prior.mean.logrr <- log(1-44.4/100)

hist(rnorm(10000, mean=prior.mean.logrr, sd=prior.sd.logrr))  #informative prior

```

For commensurate prior, need to set hyperior for variance as well. If we were to use the historical data fuklly, we would want the hyperprior for posterior variance for commensurate to approach 0. If it doesn't use it at all, we would want variance to be sufficiently large to cover negative and neutral effects

```{r}
 hist(rgamma(1000,0.01, 0.01)) # gamma hyperprior from psborrow
 mean(rgamma(1000,0.01, 0.01)) # gamma hyperprior from psborrow

  hist(rgamma(1000,0.1, 0.1)) # gamma hyperprior from psborrow
 mean(rgamma(1000,0.1, 0.1)) # gamma hyperprior from psborrow

 
   hist(rgamma(1000,1, 1)) # gamma hyperprior from psborrow
   
 mean(rgamma(1000,1, 1)) # gamma hyperprior from psborrow

    hist(rgamma(1000,10, 10)) # gamma hyperprior from psborrow
 mean(rgamma(1000,10, 10)) # gamma hyperprior from psborrow



 mean(rgamma(1000,10, 10)) # gamma hyperprior from psborrow
 var(rgamma(1000,10, 10)) # gamma hyperprior from psborrow

hist(rnorm(10000,0, rgamma(1000,1.821, 1)) )



hist(rnorm(10000,-1.2, rgamma(10000,1, 3)) )
 


#If there is no information in the new trial, then we would want it to revert to something like the skeptical prior from the original trial N(0,sd=1.821) in terms of coverage of extremes P(VE>95%)

#if prior mean= -0.5, want to have a variance that is large enough to cover null with decent probability, maybe something like a SD=2

hist(rnorm(10000, -1.2 ,2))
mean(rnorm(10000, -1.2, 2.0)< log(0.05) )
mean(rnorm(10000, -1.2, 2.0)> log(1/0.05) )

#how does this combine with a prior mean?
hist(rnorm(10000,-1.2, rgamma(10000,1, 1)) )


hist(rnorm(10000,-1.2, rgamma(10000,5, 2)) )

hist(rnorm(10000, mean=prior.mean.logrr, sd=1.8)) #infrmative mean

```

VE from Novavax. This function takes the mean and 95% CI of vaccine effectiveness, converts to a log(RR), and estimates the precision fro the CIs, assuming it is symmetric around the mean (on scale of log(RR))

```{r}
#This is main novavax result
#prior.data <- prior.data.func(ve.obs.mean=39.4, ve.obs.lcl=5.3, ve.obs.ucl=61.2, N_cases_orig =c(35,41), pop_orig= c(1430, 2765))

#Table 2: per protocol 90 day VE against RSV LRTI with hospitalization
prior.data <- prior.data.func(ve.obs.mean=44.4, ve.obs.lcl=19.6, ve.obs.ucl=61.5, N_cases_orig =c(53,57), pop_orig= c(1430, 2765))
```

Set parameters for new trial population

```{r}


#proportion of kids in placebo group who get the outcome set to 0.037 for Noavavx secondary endpoint
set.rate.control <- 0.037 

#VE in the new trial, if it agrees with original
set.ve.new.trial.agree = prior.data$ve.obs.mean

#discrepant VE in new trial (higher)
set.ve.new.trial.higher = 90

```

## Scenario 1: Same VE as original trial

Novavax had 3045 vaccinees and 1581 controls; 2.4% in placebo group had primary endpoint in 90 days

```{r}
set.seed(123)

sim1 <- sim.data.func(N.vax = 10000,
                     N.control = 10000,
                     rate.control = set.rate.control,
                     ve.new.trial=set.ve.new.trial.agree,
                     n.sim=N.sim)
  
```

## Scenario 2: no actual effect

```{r}
set.seed(456)

sim2 <- sim.data.func(N.vax = 10000,
                     N.control = 10000,
                     rate.control = set.rate.control,
                     ve.new.trial=0,
                     n.sim=N.sim)
```

## Scenario 3: discrepant actual effect

```{r}
set.seed(456)

sim3 <- sim.data.func(N.vax = 10000,
                     N.control = 10000,
                     rate.control = set.rate.control,
                     ve.new.trial=set.ve.new.trial.higher,
                     n.sim=N.sim)
```

## At which points do we want to evaluate VE?

How many vaccinees are enrolled?

```{r}

eval_points = seq(from=100, to=2000, by=100)

```

test run. 500 vaccinees+500 controls. It takes 0.27 seconds for 1 run. Need to test 20 cut points, 3 true VE levels, and 500 sims (30,000 combos). This would take 135 minutes if run sequentially.

generate combined dataset for modeling--need to fill 0s if stratum not represented

```{r}
mod.ds1 <- lapply(eval_points , function(set.pop){
    ds1 <- bind_rows(sim1, sim2, sim3) %>%
        group_by(repN,ve.new.trial, treatment) %>%
      mutate(pop=set.pop) %>%
      filter( ((ID<pop &treatment=='placebo')|(ID<pop &treatment=='vax') )) %>%
          summarize(N_cases= n(), pop=mean(pop)) %>%
      ungroup() 
    
return(ds1)
    }) %>%
  bind_rows() %>%
  tidyr::complete(repN,ve.new.trial, treatment , pop,   fill=list(N_cases=0)) %>%
    mutate( vax=if_else(treatment=='vax',1,0)) 

```

Accrual of cases in the 500 trials

```{r}
mod.ds1 %>%
  filter(ve.new.trial==44.4) %>%
  ggplot(aes(x=pop, y=N_cases, group=interaction(repN, treatment), color=treatment))+
  geom_line(alpha=0.1) +
  theme_classic()
```

Prior selection based on: <https://hbiostat.org/proj/covid19/bayesplan.html>

```{r}
ptm <- proc.time()

mod1 <- mod.ds1 %>%
  filter( repN==3  & pop==1000 &  ve.new.trial==0 ) %>%
  call_jags( prior.mean=0, prior.prec=1/1.821^2) %>%
  filter(parm=='beta1')

proc.time() - ptm


mod2 <- mod.ds1 %>%
  filter( repN==3  & pop==1000 &  ve.new.trial==0 ) %>%
  call_jags( prior.mean=0, prior.prec=1/1.821^2, model.select=model_string_commensurate_gamma) %>%
  filter(parm=='beta1')

mod3 <- mod.ds1 %>%
  filter( repN==3  & pop==1000 &  ve.new.trial==0 ) %>%
  call_jags( prior.sd.upper=100, model.select=model_string_commensurate_uniform) %>%
  filter(parm=='beta1')


mod4 <- mod.ds1 %>%
  filter( repN==3  & pop==1000 &  ve.new.trial==0 ) %>%
  call_jags( prior.mean=prior.data$log_irr.obs[1], prior.prec=1/1.821^2, model.select=model_string_commensurate_half_cauchy) %>%
  filter(parm=='beta1')



bind_rows(mod1, mod2, mod3, mod4)
```

Check dataset--shows all strata have 2 obs

```{r}

mod.ds1 %>%
  group_by(repN, ve.new.trial, pop) %>%
  summarize(n_obs=n()) %>%
  ungroup() %>%
  summarize(n_obs_range =range(n_obs))

mod.ds1.c <- mod.ds1 %>%
  reshape2::dcast(repN+ve.new.trial + pop ~ treatment, value.var='N_cases')
```

Call all models for both simulated datasets. Use parallel processing; takes \~60 min to run on 7 cores

```{r, eval=F}
ptm <- proc.time()


library(multidplyr)
ptm <- proc.time()
numCores = detectCores() -1
cluster1 <- new_cluster(numCores)
cluster_library(cluster1, "dplyr")
cluster_library(cluster1, "rjags")
cluster_library(cluster1, "HDInterval")
cluster_copy(cluster1, "call_jags")
cluster_copy(cluster1, "prior.data")
cluster_copy(cluster1, "model_string_basic_pois")
cluster_copy(cluster1, "model_string_commensurate_gamma")
cluster_copy(cluster1, "model_string_commensurate_uniform")
cluster_copy(cluster1, "model_string_commensurate_half_cauchy")


#baseline model without pooling, uninformative prior

mod0 <- mod.ds1 %>%
  group_by(repN,pop,ve.new.trial) %>%
  multidplyr::partition(cluster=cluster1)  %>%
 do(call_jags(., prior.mean=0,  prior.prec=1e-4 )) %>%
  collect() %>%
  ungroup() %>%
  mutate(Pooling_type='none', prior.info= 'N(0,1e-4)' ) 

#baseline model without pooling
mod1 <- mod.ds1 %>%
  group_by(repN,pop,ve.new.trial) %>%
  multidplyr::partition(cluster=cluster1)  %>%
 do(call_jags(. , model.select=model_string_basic_pois, prior.mean=0,  prior.prec=1/1.821^2 ) ) %>%
  collect() %>%
  ungroup() %>%
  mutate(Pooling_type='none', prior.info= 'N(0,1.821^2)')

proc.time() - ptm

ptm <- proc.time()
#Commensurate prior pooling
mod3 <- mod.ds1 %>%
  group_by(repN,pop,ve.new.trial) %>%
  multidplyr::partition(cluster=cluster1)  %>%
 do(call_jags(., prior.mean=prior.data$log_irr.obs[1], prior.prec=1/1.821^2, model.select=model_string_commensurate_gamma, set_tau_shp=3, set_tau_rate=2)) %>%
  collect() %>%
  ungroup() %>%
  mutate(Pooling_type='Commensurate', prior.info= 'N(u1,tau); IG(3,2)')

proc.time() - ptm

#Commensurate prior pooling
mod4 <- mod.ds1 %>%
  group_by(repN,pop,ve.new.trial) %>%
  multidplyr::partition(cluster=cluster1)  %>%
 do(call_jags(., prior.mean=prior.data$log_irr.obs[1], prior.prec=1/1.821^2, model.select=model_string_commensurate_gamma, set_tau_shp=1, set_tau_rate=1)) %>%
  collect() %>%
  ungroup() %>%
  mutate(Pooling_type='Commensurate', prior.info= 'N(u1,tau); IG(1,1)')

#Commensurate prior pooling
mod4 <- mod.ds1 %>%
  group_by(repN,pop,ve.new.trial) %>%
  multidplyr::partition(cluster=cluster1)  %>%
 do(call_jags(., prior.mean=prior.data$log_irr.obs[1], prior.prec=1/1.821^2, model.select=model_string_commensurate_gamma, set_tau_shp=0.01, set_tau_rate=0.01)) %>%
  collect() %>%
  ungroup() %>%
  mutate(Pooling_type='Commensurate', prior.info= 'N(u1,tau); IG(0.01,0.01)')

mod5 <- mod.ds1 %>%
  group_by(repN,pop,ve.new.trial) %>%
  multidplyr::partition(cluster=cluster1)  %>%
 do(call_jags(., prior.mean=prior.data$log_irr.obs[1], prior.prec=1/1.821^2, model.select=model_string_commensurate_uniform, prior.sd.upper=2)) %>%
  collect() %>%
  ungroup() %>%
  mutate(Pooling_type='Commensurate', prior.info= 'N(u1,tau); U(0,2)')

mod6 <- mod.ds1 %>%
  group_by(repN,pop,ve.new.trial) %>%
  multidplyr::partition(cluster=cluster1)  %>%
 do(call_jags(., prior.mean=prior.data$log_irr.obs[1], prior.prec=1/1.821^2, model.select=model_string_commensurate_uniform, prior.sd.upper=100)) %>%
  collect() %>%
  ungroup() %>%
  mutate(Pooling_type='Commensurate', prior.info= 'N(u1,tau); U(0,100)')

mod7 <- mod.ds1 %>%
  group_by(repN,pop,ve.new.trial) %>%
  multidplyr::partition(cluster=cluster1)  %>%
 do(call_jags(. , prior.mean=prior.data$log_irr.obs[1], prior.prec=1/1.821^2, model.select=model_string_commensurate_half_cauchy)) %>%
  collect() %>%
  ungroup() %>%
  mutate(Pooling_type='Commensurate', prior.info= 'N(u1,tau);t(0,1,1)T(0,)')


proc.time() - ptm

all.mods <- bind_rows(mod0,mod1, mod3, mod4, mod5, mod6, mod7)

saveRDS(all.mods, './Results/all.mods_novavax.rds')

ptm <- proc.time()

```

```{r}
all.mods <- readRDS( './Results/all.mods_novavax.rds') %>%
  rename(parm_mean=mean) %>%
  mutate(  parm_mean = if_else( parm_mean< (-4), (-4), 
                  if_else(parm_mean> 4,4, parm_mean)),
          lcl = if_else(lcl< (-4), (-4), 
                  if_else(lcl>4,4, lcl)),
           ucl = if_else(ucl< (-4), (-4), 
                  if_else(ucl>4,4, ucl))
         
  )

```

## Bayesian estimates of performance

```{r}

#the p_xx are replicated for each parameter so filter to just 1 parameter
probs <- all.mods %>% 
  group_by(repN, pop, ve.new.trial,Pooling_type,prior.info) %>%
  filter(parm=='beta1')  %>%
  ungroup()
```

### Trajectories of P(benefit) for a subset of trials

This shows how the probabilities evolve as more data accrue. This shows probability of any benefit: P(VE\>0\|data)

```{r}
probs %>%
  filter(ve.new.trial==44.4 & Pooling_type != 'Full' & repN %in% c(1:10)) %>%
  mutate(prior.info = as.factor(prior.info)) %>%
  
ggplot( aes(x=pop, y=p_0, group=interaction(repN,prior.info), color=Pooling_type)) +
  geom_line( alpha=0.1) +
  theme_classic() +
  facet_wrap(~prior.info)
```

### Bayesian power for fixed sample size

What proportion of trials would have a P(benefit\>0.95\|data) at different sample sizes?

for each trial, call 0/1 based on if we have hit 0.95 at this sample size or earlier

```{r, fig.width=4, fig.height=2}
power1 =probs %>%
  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN,  ve.new.trial,prior.info) %>%
  mutate( eff_0 = if_else(p_0>0.95,1,0),
          eff_0_p99 = if_else(p_0>0.99,1,0),
          eff_0_p97 = if_else(p_0>0.98,1,0),
          eff_0_p98 = if_else(p_0>0.97,1,0),

                    eff_0_p96 = if_else(p_0>0.96,1,0),
          eff_5 = if_else(p_0_95>0.95,1,0),
          eff_10 = if_else(p_0_90>0.95,1,0),
          eff_15 = if_else(p_0_85>0.95,1,0),
          eff_20 = if_else(p_0_80>0.95,1,0),
          eff_25 = if_else(p_0_75>0.95,1,0),
          eff_30 = if_else(p_0_70>0.95,1,0),
          futile_30 = if_else(p_futile>0.95,1,0),
            ) %>%
  ungroup() %>%
  group_by(pop, ve.new.trial,prior.info) %>%
    summarize(prop_eff_0 = mean(eff_0),
              prop_eff_0_p99=mean(eff_0_p99),
              prop_eff_0_p98=mean(eff_0_p98),
              prop_eff_0_p97=mean(eff_0_p97),
              prop_eff_0_p96=mean(eff_0_p96),

                            prop_eff_5 = mean(eff_5),
            prop_eff_10 = mean(eff_10),
            prop_eff_15 = mean(eff_15),
            prop_eff_20 = mean(eff_20),
              prop_eff_25 = mean(eff_25),
              prop_eff_30 = mean(eff_30),
              prop_futile_30 = mean(futile_30),
              )        
```


```{r, fig.width=4, fig.height=2}

power1 %>%
  filter(prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%
ggplot(aes( x=pop, y=prop_eff_0, group=prior.info, color=prior.info, lty=prior.info)) +
  geom_line() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Proportion of trials with >95% probability that effect is >0% VE')
```

Figure S1

```{r, fig.width=4, fig.height=2}

power1 %>%
ggplot(aes( x=pop, y=prop_eff_0, group=prior.info, color=prior.info)) +
  geom_line() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Proportion of trials with >95% probability that effect is >0% VE')
```

P VE \>10%


Figure 2
```{r, fig.width=4, fig.height=2}
power1 %>%
    filter(prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%
ggplot(aes( x=pop, y=prop_eff_10, group=prior.info, color=prior.info, lty=prior.info)) +
  geom_line() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Proportion of trials with >95% probability that effect is >10% VE')
```

Figure S2
```{r, fig.width=4, fig.height=2}
power1 %>%
ggplot(aes( x=pop, y=prop_eff_10, group=prior.info, color=prior.info)) +
  geom_line() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Proportion of trials with >95% probability that effect is >10% VE')
```

P VE \>0%>0.99

Figure 3
```{r, fig.width=4, fig.height=2}

p1 <- power1 %>%
      filter(prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%
ggplot(aes( x=pop, y=prop_eff_0_p99, group=prior.info, color=prior.info, lty=prior.info)) +
  geom_line() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Proportion of trials with >99% probability that effect is >0% VE')

p1
ggplotly(p1)
```

Figure S3
```{r, fig.width=4, fig.height=2}

power1 %>%
ggplot(aes( x=pop, y=prop_eff_0_p99, group=prior.info, color=prior.info)) +
  geom_line() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Proportion of trials with >99% probability that effect is >0% VE')
```

P Futile (VE \<30%)

Figure S4
```{r, fig.width=4, fig.height=2}
power1 %>%
        filter(prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%

ggplot(aes( x=pop, y=prop_futile_30, group=prior.info, color=prior.info, lty=prior.info)) +
  geom_line() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Proportion of trials with >95% probability that effect is <30% VE')
```

Figure S4
```{r, fig.width=4, fig.height=2}
power1 %>%
ggplot(aes( x=pop, y=prop_futile_30, group=prior.info, color=prior.info)) +
  geom_line() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Proportion of trials with >95% probability that effect is <30% VE')
```


### Bayesian power for sequential trial with looks every 500 people

Figure 6. Evaluate cumulative probability of hitting the (P(VE>15%)>0.95)

```{r, fig.width=6, fig.height=3}
stopped_efficacy1 =probs %>%
  filter(pop %in% c(500, 1000,1500, 2000) & prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%
  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN,  ve.new.trial,prior.info) %>%
  mutate( eff = 1*(p_0_90>0.98),
            stop = cumsum(eff) ,
          stop = if_else(stop>=1,1,0)) %>%
  ungroup() %>%
  group_by(pop, ve.new.trial,prior.info) %>%
    summarize(prop_stopped = mean(stop))        


p1a <- stopped_efficacy1 %>%
ggplot(aes( x=pop, y=prop_stopped, group=prior.info, color=prior.info)) +
  geom_line() +
    geom_point() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Cumulative proportion with >98% prob that effect is >10%VE')
ggplotly(p1a)
p1a
```
Figure S7

```{r, fig.width=6, fig.height=3}
stopped_efficacy1 =probs %>%
  filter(pop %in% c(500, 1000,1500, 2000) ) %>%
  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN,  ve.new.trial,prior.info) %>%
  mutate( eff = 1*(p_0_90>0.98),
            stop = cumsum(eff) ,
          stop = if_else(stop>=1,1,0)) %>%
  ungroup() %>%
  group_by(pop, ve.new.trial,prior.info) %>%
    summarize(prop_stopped = mean(stop))        


p1a <- stopped_efficacy1 %>%
ggplot(aes( x=pop, y=prop_stopped, group=prior.info, color=prior.info)) +
  geom_line() +
    geom_point() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Cumulative proportion with >98% prob that effect is >10%VE')
ggplotly(p1a)
p1a
```


Same thresholds but evaluate after every 100 
```{r, fig.width=6, fig.height=3}
stopped_efficacy1 =probs %>%
  filter(pop %in% seq(500, 2000, by=100) & prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%
  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN,  ve.new.trial,prior.info) %>%
  mutate( eff = 1*(p_0_90>0.99),
            stop = cumsum(eff) ,
          stop = if_else(stop>=1,1,0)) %>%
  ungroup() %>%
  group_by(pop, ve.new.trial,prior.info) %>%
    summarize(prop_stopped = mean(stop))        


p1a <- stopped_efficacy1 %>%
ggplot(aes( x=pop, y=prop_stopped, group=prior.info, color=prior.info)) +
  geom_line() +
    geom_point() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Cumulative proportion with >98% prob that effect is >10%VE')
ggplotly(p1a)
p1a
```


```{r}
 stopped_efficacy1 =probs %>%
    filter(pop %in% c(500, 1000,1500, 2000)) %>%

  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN,  ve.new.trial,prior.info) %>%

  mutate( eff = 1*(p_0_90>0.95),
            stop = cumsum(eff) ,
          stop = if_else(stop>=1,1,0)) %>%
  ungroup() %>%
  group_by(pop, ve.new.trial,prior.info) %>%
    summarize(prop_stopped = mean(stop))        


p1b <- stopped_efficacy1 %>%
ggplot(aes( x=pop, y=prop_stopped, group=prior.info, color=prior.info)) +
  geom_line() +
    geom_point() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray') +
  ggtitle('Cumulative proportion with >95% prob that effect is >10%VE')

p1b
```





Futility

```{r,fig.width=6, fig.height=3}
stopped_futility =probs %>%
    filter(pop %in% c(500, 1000,1500, 2000)) %>%
  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN, pop, ve.new.trial,prior.info) %>%
  mutate( fut = 1*((1-p_0)>0.5),
            stop = cumsum(fut) ,
          stop = if_else(stop>=1,1,0)) %>%
  ungroup() %>%
  group_by(pop, ve.new.trial,prior.info) %>%
    summarize(prop_stopped = mean(stop))        


ggplot(stopped_futility, aes( x=pop, y=prop_stopped, group=prior.info, color=prior.info)) +
  geom_line() +
  geom_point() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')
```


## Adjust threshold for Type I error control

for a single point

```{r, fig.width=6, fig.height=3}

#First figure out what cutoff should be when true VE=0 (ve.new.trial) to get 5% Type 1 error rate
cutoff =probs %>%
  filter(pop %in% seq(500, 2000, by=100) & prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%
  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN,  ve.new.trial,prior.info,pop) %>%
    ungroup() %>%
  group_by(pop, ve.new.trial,prior.info) %>%
  filter(ve.new.trial==0) %>%
  summarize(p_cutoff= quantile(p_0,probs=0.95)) %>%  #what quantile of P(VE>0%|Data) captures 95% of the trials? 
  ungroup() %>%
  select(p_cutoff,pop, prior.info,pop)
  
cutoff

    #Then merge in and apply this cutoff for different VE
stopped_efficacy1 =probs %>%
   right_join(cutoff, by=c( 'prior.info', 'pop')) %>%
  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN,  ve.new.trial,prior.info,pop) %>%

  mutate( eff = 1*(p_0>p_cutoff))%>%
  ungroup() %>%
  group_by(pop, ve.new.trial,prior.info) %>%
    summarize(prop_stopped = mean(eff))


p1a <- stopped_efficacy1 %>%
ggplot(aes( x=pop, y=prop_stopped, group=prior.info, color=prior.info)) +
  geom_line() +
    geom_point() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Power and type I error withcontrol for type I error; single evaluation')
ggplotly(p1a)
p1a


p1b <- cutoff %>%
ggplot(aes( x=pop, y=p_cutoff, group=prior.info, color=prior.info)) +
  geom_line() +
    geom_point() +
  theme_classic() +
  geom_hline(yintercept = c(0.95), lty=2, col='gray')+
  ggtitle('P cutoff with control for type I error; single evaluation')
ggplotly(p1b)
p1b

ave.p <- cutoff %>%
  group_by(prior.info) %>%
  summarize(p_cutoff=mean(p_cutoff))
ave.p

```

or do it sequentially

```{r, fig.width=6, fig.height=3}

start.pop <- 500
look.interval <- 100

cutoff =probs %>%
  filter(pop %in% start.pop & prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" ) & ve.new.trial ==0 ) %>%
  group_by(pop, ve.new.trial,prior.info) %>%
  summarize(p_cutoff= quantile(p_0,probs=0.95)) %>%  #what quantile of P(VE>0%|Data) captures 95% of the trials? 
  ungroup() %>%
  select(p_cutoff, prior.info) %>% #there is only 1 pop level here
  mutate(p_cutoff_pop = start.pop)




threshold_finder_sequential <- function(eval.points = seq(500,2000, by=100)){
  
    probs.cum = probs %>%
        filter(pop %in% eval.points & prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" ) & ve.new.trial ==0) %>%
      arrange(prior.info, ve.new.trial, repN, pop)
  
   cut.list <- list()
    
  for(i in 1:length(eval.points)){
      #on this first poiunt, determine cutoff to get 5% Type I error rate
  
      #Establish cutoff for the current trial size
      cut_points =probs.cum %>%
        filter(pop == eval.points[i] ) %>%
        group_by(pop, prior.info) %>%
        summarize(p_cutoff= quantile(p_0,probs=0.95)) %>%  #what quantile of P(VE>0%|Data) captures 95% of the trials? 
        ungroup() %>%
        select(p_cutoff, prior.info) %>% 
        mutate(pop.current=eval.points[i] ) #if
      
      cut.list[[i]] <- cut_points
      
      #If stop has been triggered by previous time points and its cutoff, set to 1 for next         iteration
      stopped_current <- probs.cum %>%
       right_join(cut_points, by=c( 'prior.info', 'pop'='pop.current')) %>%
        filter( pop == eval.points[i] ) %>%
       arrange( ve.new.trial,prior.info, repN,pop ) %>%
       group_by(ve.new.trial,prior.info, repN) %>%
       mutate( p_cutoff = if_else(is.na(p_cutoff),999, p_cutoff), 
         stopped = if_else(  p_0>=p_cutoff , 1, 0) #P_0 set to 1 if trial already crossed threshold
         ) %>%
        filter(pop==eval.points[i]) %>%
        ungroup() %>%
        select(prior.info, repN, stopped) 
      
      if(i==1){
        probs.cum$stopped <- NA
      }
  
      # when it has been stopped in current or previous times, set p_0 for next point to 1
      probs.cum <- probs.cum %>%
        select(-stopped) %>% #remove prev version of this
        left_join(stopped_current, by=c('prior.info','repN')) %>%
        mutate(p_0 = if_else(stopped==1 & pop<=eval.points[i+1], 1, p_0))
      
      
      # probs.cum2 <- probs.cum %>%
      #  # select(-stopped) %>% #remove prev version of this
      #   left_join(stopped_current, by=c('prior.info','repN')) %>%
      #     arrange(prior.info, repN, pop) %>%
      #   mutate(p_0 = if_else(stopped==1 , 1, p_0))
      
  }
  
    cuts <- bind_rows(cut.list)  %>%
      rename(pop=pop.current)
    return(cuts)
}


cuts <- threshold_finder_sequential(eval.points = seq(500,2000, by=100)) 


p1a <- cuts %>%
ggplot(aes( x=pop, y=p_cutoff, group=prior.info, color=prior.info)) +
  geom_line() +
    geom_point() +
  theme_classic() +
  geom_hline(yintercept = c(0.95), lty=2, col='gray')+
  ggtitle('Cumulative proportion with >X% prob that effect is >0%VE')
ggplotly(p1a)
p1a
```


### Observed data vs estimate


Observed
```{r}
 obs_data <- mod.ds1.c %>%
  mutate( obs_RR = vax/placebo ) 
```

```{r}
obs_data %>%
  filter(ve.new.trial==44.4)  %>%
  ggplot( aes(x=pop, y=obs_RR, group=repN)) +
  geom_line(alpha=0.1) +
  theme_classic() +
  ylim(0.2, 2)
```

```{r}
obs_exp_data <-   obs_data %>%
  left_join(probs, by=c('repN','pop','ve.new.trial')) 

obs_exp_data %>%
  filter(ve.new.trial==44.4 & prior.info=="N(0,1e-4)") %>%
  ggplot(aes(x=log(obs_RR), y=parm_mean)) +
  geom_point() +
  theme_classic()

obs_exp_data %>%
  filter(ve.new.trial==44.4 & prior.info=="N(u1,tau); IG(0.01,0.01)") %>%
  ggplot(aes(x=log(obs_RR), y=parm_mean)) +
  geom_point() +
  theme_classic()

```

Probability of success as a function of number of events

```{r}
obs_exp_data %>%
  filter(ve.new.trial==44.4 & prior.info=="N(u1,tau); IG(0.01,0.01)") %>%
  mutate(tot_events=placebo+vax) %>%
   ggplot(aes(x=tot_events, y=p_0)) +
  geom_point() +
  theme_classic()

```


```{r}
probs %>%
  filter(ve.new.trial==44.4 ) %>%
  mutate(Pooling_type = as.factor(Pooling_type)) %>%
ggplot( aes(x=pop, y=parm_mean, group=repN, color=Pooling_type)) +
  geom_line( alpha=0.1) +
  theme_classic() +
  ylim(-4,4)+
  facet_wrap(prior.info~Pooling_type)
```


### How do probs from a single trial evolve as data accrue?
```{r}
probs %>%
    left_join(obs_data, by=c('repN','pop','ve.new.trial')) %>%
  filter(ve.new.trial==44.4 & Pooling_type != 'Full' & repN==3 & prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%
  mutate(Pooling_type = as.factor(Pooling_type)) %>%
ggplot( aes(x=pop, y=exp(parm_mean), group=interaction(repN,prior.info))) +
  geom_line( alpha=1) +
  theme_classic() +
   geom_ribbon( aes(x=pop, ymin=exp(lcl), 
                   ymax=exp(ucl)), alpha=0.1) +
  facet_wrap(~prior.info) +
  geom_line(aes(x=pop, y=obs_RR), color='black', lty=3)+
  ylim(-4,4) +
  geom_hline(yintercept=1, lty=2)
```


## Average sample size before stopping
```{r}
stopped_pop1 =probs %>%
  filter(pop %in% seq(500, 2000, by=100) & prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%
  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN,  ve.new.trial,prior.info) %>%
  mutate( eff = 1*(p_0_90>0.99),
            stopN = cumsum(eff),
          stop = if_else(stopN>=1,1,0),
          stop_pop=if_else(stopN==1,pop, NA_real_))%>%
  ungroup() 

stopped_pop1 %>%
  filter(ve.new.trial == 44.4 ) %>%
ggplot( aes(x=stop_pop)) +
  geom_histogram() +
  facet_wrap(ve.new.trial~prior.info)
```

```{r}

stopped_pop1 %>%
   group_by(ve.new.trial,prior.info) %>%
     summarize( pop_stop=mean(stop_pop, na.rm=T)) %>%
   mutate(pop_stop= if_else(is.nan(pop_stop),2000, pop_stop))

```




## Compare type 1 error control with without historical data on sequential trial

This largely confirms Kopp-Schneider A, Calderazzo S, Wiesenfarth M. Power gains by using external information in clinical trials are typically not possible when requiring strict type I error control. Biom J. 2020;62(2):361–74.

If not using historical data, need to have a probability cutoff of 0.975 to control type 1 error (<0.05 if go to 2000). With this, need 2000 vaccinees to get power of 0.78 for prior without historical data. 

```{r, fig.width=6, fig.height=3}
stopped_efficacy1 =probs %>%
  filter(pop %in% seq(500, 2000, by=100) & prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%
  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN,  ve.new.trial,prior.info) %>%
  mutate( eff = 1*(p_0_90>0.975),
            stop = cumsum(eff) ,
          stop = if_else(stop>=1,1,0)) %>%
  ungroup() %>%
  group_by(pop, ve.new.trial,prior.info) %>%
    summarize(prop_stopped = mean(stop))        


p1a <- stopped_efficacy1 %>%
ggplot(aes( x=pop, y=prop_stopped, group=prior.info, color=prior.info)) +
  geom_line() +
    geom_point() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Cumulative proportion with >97.5% prob that effect is >10%VE')
ggplotly(p1a)
p1a
```

In contrast, if controlling type 1 error for informative prior, need to increase P to 0.99, and with IG(0.01,0.01) would need 1900 people, so very little efficiency gain
```{r, fig.width=6, fig.height=3}
stopped_efficacy1 =probs %>%
  filter(pop %in% seq(500, 2000, by=100) & prior.info %in% c("N(0,1.821^2)", "N(u1,tau); IG(0.01,0.01)", "N(u1,tau); U(0,2)" )) %>%
  arrange(repN, ve.new.trial,prior.info ,pop) %>%
 group_by(repN,  ve.new.trial,prior.info) %>%
  mutate( eff = 1*(p_0_90>0.99),
            stop = cumsum(eff) ,
          stop = if_else(stop>=1,1,0)) %>%
  ungroup() %>%
  group_by(pop, ve.new.trial,prior.info) %>%
    summarize(prop_stopped = mean(stop))        


p1a <- stopped_efficacy1 %>%
ggplot(aes( x=pop, y=prop_stopped, group=prior.info, color=prior.info)) +
  geom_line() +
    geom_point() +
  facet_wrap(~ ve.new.trial) +
  theme_classic() +
  geom_hline(yintercept = c(0.05, 0.8), lty=2, col='gray')+
  ggtitle('Cumulative proportion with >99% prob that effect is >10%VE')
ggplotly(p1a)
p1a
```